{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d955e543",
   "metadata": {},
   "source": [
    "# Developing Depression Risk Prediction Models\n",
    "## Using the National Health and Nutrition Examination Survey Data 2013-2014\n",
    "\n",
    "Group 2: Bei Wang, Fangyuan Zhao, Kat Hutcheson,  Amro Hassan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80fe0eb",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9ea22",
   "metadata": {},
   "source": [
    "In the US, it is estimated that almost ten million people suffer from depression, while only one-third of them received appropriate treatment. Social service and health care professionals are well-situated to assess depression risk of their clients or patients during brief encounters. But this has been challenging because people who are at higher risk of mental disorders might be reluctant to respond to standardized questionnaires (e.g. PHQ-2 and PHQ-9) for depression screening. Moreover, there is no efficient and user-friendly predictive tool for this purpose. \n",
    "\n",
    "Therefore, our ***main goal*** is to build an efficient depression risk prediction model for social service and healthcare practitioners to use to screen people who might be at risk of depression. Our ***second aim*** is to examine whether people of different racial/ethnic backgrounds have different predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd9c9f",
   "metadata": {},
   "source": [
    "# 2. Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00221f6",
   "metadata": {},
   "source": [
    "We used the National Health and Nutrition Examination Survey (NHANES, 2013-2014) initiated by the Centers for Disease Control and Prevention (CDC) and the National Center for Health Statistics (NCHS). The NHANES aims to provide US national health data on the prevalence of major diseases and associated risk factors among adults and children. \n",
    "\n",
    "In our present project, we focus on NHANES survey questions that would be easy to ask in brief health care or social service encounters and does not require lengthy and expensive tests. Based on this criteria, we narrowed down to 1166 features in aspects of demographic, socioeconomic, dietary, socio-psychological, behavioral health, medical conditions, functional health, and life experience. \n",
    "\n",
    "We further selected features and applied several supervised learning techniques to develop a model with the best prediction performance. Our final model contains 20 features. **Please see our documentation for full details of our method.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1940a6",
   "metadata": {},
   "source": [
    "# 3. Prepare and explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d840d",
   "metadata": {},
   "source": [
    "##  3.1 Merge data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa45c515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from functools import reduce\n",
    "import os\n",
    "from dmba import classificationSummary\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#imputation \n",
    "from sklearn.impute import SimpleImputer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7a3fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/beiw/Google Drive/PHS@UChicago/2021 Autumn/data mining/project/final submission of project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffc4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not including medications\n",
    "os.chdir('/Users/beiw/Google Drive/PHS@UChicago/2021 Autumn/data mining/project/data')\n",
    "files= ['demographic.csv', 'diet.csv', 'questionnaire.csv'] #only use demo, diet, and questionnaire \n",
    "demo= pd.read_csv('demographic.csv')\n",
    "diet= pd.read_csv('diet.csv')\n",
    "qr= pd.read_csv('questionnaire.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e285c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo (10175, 47)\n",
      "diet (9813, 168)\n",
      "ques (10175, 953)\n"
     ]
    }
   ],
   "source": [
    "print('demo', demo.shape)\n",
    "print('diet', diet.shape)\n",
    "print('ques', qr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c342e8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged df shape: (9813, 1166)\n"
     ]
    }
   ],
   "source": [
    "ls=[]\n",
    "for file in files: \n",
    "    df= pd.read_csv(file)\n",
    "    ls.append(df)\n",
    "df_merge= reduce(lambda x,y: pd.merge(x, y,  how='inner', on= 'SEQN', suffixes=('', '_drop')), ls)\n",
    "df_merge.drop([col for col in df_merge.columns if 'drop' in col], axis=1, inplace=True)\n",
    "print(\"merged df shape:\", df_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1776d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9813\n",
       "Name: SEQN, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicated SEQN\n",
    "df_merge.SEQN.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42205e3",
   "metadata": {},
   "source": [
    "### Get a codebook for the dataset for meaning of features\n",
    "This was done in a seperate files; some of the variables names are inconsistent, resulting in NaN, so I changed them manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130fac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbook= pd.read_csv('nhanes_2013_2014_codebook.csv')\n",
    "#convert variable names to upper class to match with df_merge\n",
    "cbook['variable']= cbook['variable'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3054b7df",
   "metadata": {},
   "source": [
    "## 3.2 Missingness \n",
    "Missing data in the dataset are all represented in 7s and 9s. We drop observations that have missing data in the target variable (phq9), which results in 3657 unique observations. Among the rest of the features, we drop those with more than 20% missing data or those are non-numeric, which results in 502 features. Within the dataset that has minimized missingness, we further prepare the data set by imputing the rest of the missingness using the most_frequent method in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a232bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all 7s and 9s as null \n",
    "df_merge.replace({7:None, 9:None, 77:None,99:None,777:None,999:None,7777:None,9999:None,77777:None,99999:None,\n",
    "            777777:None,999999:None,55:None,555:None,5555:None,8:None,88:None}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd2b60c",
   "metadata": {},
   "source": [
    "### Drop observations with missingness in target feature\n",
    "The target feature is PHQ9, which consists of 10 features from DPQ010 to DPQ100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4fd4ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of 0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       NaN\n",
       "4       3.0\n",
       "       ... \n",
       "9808    0.0\n",
       "9809    NaN\n",
       "9810    NaN\n",
       "9811    NaN\n",
       "9812    NaN\n",
       "Name: DPQ050, Length: 9813, dtype: float64>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "df_merge.DPQ050.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93dfd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create phq9 scores and drop rows with any item missing \n",
    "df_merge['phq9']= df_merge[['DPQ010','DPQ020','DPQ030','DPQ040', 'DPQ050', 'DPQ060', 'DPQ070', 'DPQ080', 'DPQ090']].sum(axis=1, skipna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46eb2c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prep for visualization, assign categories to the original data and data after remving missing phq9 scores\n",
    "orig = df_merge #original data set to be used for comparison\n",
    "orig['DataSet'] = np.where(df_merge['phq9'].notna(), 'Cleaned Data', 'Original Data')  #add column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedfcdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5372, 1168)\n"
     ]
    }
   ],
   "source": [
    "#drop rows with any item missing for phq9 \n",
    "\n",
    "df_merge= df_merge[df_merge['phq9'].notna()]\n",
    "print(df_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3277676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5372.000000\n",
       "mean        3.311616\n",
       "std         4.396482\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         2.000000\n",
       "75%         5.000000\n",
       "max        27.000000\n",
       "Name: phq9, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.phq9.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a627be0",
   "metadata": {},
   "source": [
    "### Compare the Amount of Records by Ethnicity (pre and post dropping missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14957bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "font1 = {'family':'calibri','color':'darkgray','size':18}\n",
    "font2 = {'family':'calibri','color':'black','size':22}\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "ct = pd.crosstab(orig.RIDRETH3, orig.DataSet)\n",
    "    \n",
    "ax = ct.plot(kind='bar', stacked=True, rot= 45)\n",
    "ax.legend(ncol=1, shadow=True, loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "\n",
    "\n",
    "plt.xlabel(\"Ethnicity\", fontdict=font1)\n",
    "plt.ylabel(\"Count of Records\", fontdict = font1)\n",
    "plt.title(\"Figure 5. Data Set Comparison by Ethnicity\", fontdict = font2)\n",
    "ax.set_xticklabels(['Mexican American', 'Other Hispanic', 'non-H White', 'non-H Black', 'non-H Asian'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64a3e0",
   "metadata": {},
   "source": [
    "When reviewing the % of data removed due to missing values, the records for non-H White had a higher % of their original data represented (48%) vs other ethnicities only having 30-35% of their original data included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ac0f4",
   "metadata": {},
   "source": [
    "### Drop feature columns with more than 20% missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4884cb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop columns with more than no missing data\n",
    "df_merge= df_merge.dropna(thresh= 0.8*len(df_merge), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ada07",
   "metadata": {},
   "source": [
    "### Drop non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09a954dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 columns left\n"
     ]
    }
   ],
   "source": [
    "# exclude non-numeric values\n",
    "df_merge = df_merge.select_dtypes(['number'])\n",
    "print(len(df_merge.columns), 'columns left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88fc015e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5372 entries, 0 to 9808\n",
      "Columns: 291 entries, SEQN to phq9\n",
      "dtypes: float64(278), int64(13)\n",
      "memory usage: 12.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_merge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc01c3",
   "metadata": {},
   "source": [
    "### Impute missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bafccb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mode=SimpleImputer(strategy='most_frequent')\n",
    "df_merge = pd.DataFrame(imp_mode.fit_transform(df_merge), columns=df_merge.columns)\n",
    "#could try other imputation method KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c905779",
   "metadata": {},
   "source": [
    "## 3.3 Feature selection (initial selection)\n",
    "\n",
    "To achieve our goal of building a model with questions that are brief and easy to ask, we went through a manual selection of features. This step includes dropping administration-related features (e.g., language of interview, interpreter code), features that require lengthy dietary assessments, and duplicated questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc9b98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go over the dictionary manually and drop the unwanted variables\n",
    "col = df_merge.columns\n",
    "df_col = cbook[cbook['variable'].isin(col)]\n",
    "df_col.to_csv(r'df_col.csv') #done in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48160d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove variables that are related to administration/operation (e.g. language of interview, interpreter code)\n",
    "#admin = pd.read_csv('C:/Users/AmroHassan/Google Drive/Classroom/31008 1-Data Mining Principles/Project/Depression-risk-main/Project Data/Depression-risk-main/data/administrative_col.csv')\n",
    "admin = pd.read_csv('administrative_col.csv')\n",
    "admin_col = admin.columns\n",
    "df_merge = df_merge.drop(admin.columns, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "794702ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'diet_col.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-06f1fbbcc522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#(e.g. Total bottled water drank yesterday)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#dietary = pd.read_csv('C:/Users/AmroHassan/Google Drive/Classroom/31008 1-Data Mining Principles/Project/Depression-risk-main/Project Data/Depression-risk-main/data/diet_col.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdietary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diet_col.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdiet_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdietary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf_merge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_merge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdietary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diet_col.csv'"
     ]
    }
   ],
   "source": [
    "#remove variables that are collected and calculated after very detailed Dietary Interviews\n",
    "#(e.g. total dietary fiber)\n",
    "#Can keep variables that can be easily answered\n",
    "#(e.g. Total bottled water drank yesterday)\n",
    "#dietary = pd.read_csv('C:/Users/AmroHassan/Google Drive/Classroom/31008 1-Data Mining Principles/Project/Depression-risk-main/Project Data/Depression-risk-main/data/diet_col.csv')\n",
    "dietary = pd.read_csv('diet_col.csv')\n",
    "diet_col = dietary.columns\n",
    "df_merge = df_merge.drop(dietary.columns, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c015d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove one of HUQ010 and HSD010 (identical question asked in different surveys, highly correlated)\n",
    "df_merge = df_merge.drop('HUQ010', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a487e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv(r'df_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd65d7",
   "metadata": {},
   "source": [
    "Now, after cleaning, only 211 columns left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8717a00d",
   "metadata": {},
   "source": [
    "## 3.4 Target variable (PHQ9) definition and visualization\n",
    "\n",
    "The PHQ-9 was found to have acceptable diagnostic properties for detecting major depressive disorder for cut-off scores between 8 and 11. We explore this variable in two different ways: \n",
    "\n",
    "* PHQ9 itself is a numeric feature with a possible range from 0 to 27\n",
    "* PHQ9 was dichotomized in (>=8/<8) to determine depression\n",
    "* We also explored more restrict thresholds that have been used conventionally to define depression such as moderate and severe depression. \n",
    "* We further explored frequencies of suicidal ideation. \n",
    "* We end up using the \">=8/<8\" threshold to define depression in the current project for the other definitions result in too few cases of depression to develop a prediction model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed3e7f",
   "metadata": {},
   "source": [
    "#### Numeric PHQ9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200953e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(df_merge.phq9, discrete=True)\n",
    "plt.xlabel(\"Numeric PHQ9 Score\", fontdict=font1)\n",
    "plt.ylabel(\"Count of Records\", fontdict = font1)\n",
    "plt.title(\"Figure 2. Distribution of PHQ9 Score\", fontdict = font2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c40cfb",
   "metadata": {},
   "source": [
    "#### Depression (dichotomized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe76cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['mild_dep']= np.where(df_merge['phq9']>=8,1,0)\n",
    "print('mild', df_merge['mild_dep'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9664f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = sns.countplot(x='mild_dep', data = df_merge, palette = \"GnBu\")\n",
    "dx.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "dx.set_xlabel(\"PHQ9 Category\", fontdict=font1)\n",
    "dx.set_title('Figure 3. Depression Count (phq9>=8)', y=1.03, fontdict=font2)\n",
    "dx.set_xticklabels(['Non- Dep','Dep'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bcd82c",
   "metadata": {},
   "source": [
    "#### Moderate depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['mod_dep']= np.where(df_merge['phq9']>=15,1,0)\n",
    "print('modereate', df_merge['mod_dep'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd045a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = sns.countplot(x='mod_dep', data = df_merge, palette = \"GnBu\")\n",
    "dx.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "dx.set_xlabel(\"PHQ9 Category\", fontdict=font1)\n",
    "dx.set_title('Mod Depression Count', y=1.03, fontdict=font2)\n",
    "dx.set_xticklabels(['Non-Mod Dep','Mod Dep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c924b",
   "metadata": {},
   "source": [
    "#### Severe depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['sev_dep']= np.where(df_merge['phq9']>=20,1,0)\n",
    "print('severe', df_merge['sev_dep'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = sns.countplot(x='sev_dep', data = df_merge, palette = \"GnBu\")\n",
    "dx.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "dx.set_xlabel(\"PHQ9 Category\", fontdict=font1)\n",
    "dx.set_title('Severe Depression Count', y=1.03, fontdict=font2)\n",
    "dx.set_xticklabels(['Non-Sev Dep','Sev Dep'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55eeb6",
   "metadata": {},
   "source": [
    "#### Suicidal ideation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93318b17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge['suicidal']= np.where(df_merge['DPQ090']>0,1,0)\n",
    "print('suicidal', df_merge['suicidal'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f59523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dx = sns.countplot(x='suicidal', data = df_merge, palette = \"GnBu\")\n",
    "dx.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "dx.set_xlabel(\"PHQ9 Category\", fontdict=font1)\n",
    "dx.set_title('Suicidal Depression Count', y=1.03, fontdict=font2)\n",
    "dx.set_xticklabels(['Non-Suicidal','Suicidal'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e749b1",
   "metadata": {},
   "source": [
    "## 3.4 Other key features exploration\n",
    "We explored other key demographic features to describe this population. \n",
    "\n",
    "* A large proportion of the population is non-Hispanic white while there are also Hispanics, non-Hispanic blacks, and non-Hispanic Asians. \n",
    "\n",
    "* People's age ranges from 18 to 80 with larger proportions of the youngest and the oldest group. \n",
    "\n",
    "* There are more females than males. This population is also highly educated. About a quarter of the population was not US-born. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15e19c",
   "metadata": {},
   "source": [
    "### Race and ethnicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = sns.countplot(x='RIDRETH3', data = df_merge, palette = \"GnBu\")\n",
    "dx.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "dx.set_xlabel(\"Ethnicity\", fontdict=font1)\n",
    "dx.set_title('Records by Ethnicity', y=1.03, fontdict=font2)\n",
    "dx.set_xticklabels(['Mexican American', 'Other Hispanic', 'non-H White', 'non-H Black', 'non-H Asian'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e7b9a",
   "metadata": {},
   "source": [
    "### Explore Age, Education, Country of Birth, and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(9, 9))\n",
    "font1 = {'family':'calibri','color':'gray','size':10}\n",
    "font2 = {'family':'calibri','color':'black','size':15}\n",
    "\n",
    "d1=sns.histplot(data=df_merge, x=\"RIDAGEYR\", kde=True, color=\"skyblue\", ax=axs[0, 0])\n",
    "d2=sns.countplot(data=df_merge, x=\"RIAGENDR\", palette=\"GnBu\", ax=axs[0, 1])\n",
    "d3=sns.countplot(data=df_merge, x=\"DMDBORN4\", palette='GnBu', ax=axs[1, 0])\n",
    "d4=sns.countplot(data=df_merge, x=\"DMDEDUC2\", palette=\"GnBu\", ax=axs[1, 1])\n",
    "\n",
    "d1.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "d1.set_xlabel(\"Age in Years\", fontdict=font1)\n",
    "d1.set_title('Age', y=1.03, fontdict=font2)\n",
    "\n",
    "\n",
    "d2.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "d2.set_xlabel(\"Gender\", fontdict=font1)\n",
    "d2.set_title('Gender', y=1.03, fontdict=font2)\n",
    "d2.set_xticklabels(['Male (1)','Female (2)'])\n",
    "\n",
    "d3.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "d3.set_xlabel(\"Country of Birth\", fontdict=font1)\n",
    "d3.set_title('Country of Birth', y=1.03, fontdict=font2)\n",
    "d3.set_xticklabels(['United States (1)','Not in United States (2)'])\n",
    "\n",
    "d4.set_ylabel(\"Count of Records\", fontdict = font1)\n",
    "d4.set_xlabel(\"Level\", fontdict=font1)\n",
    "d4.set_title('Education Attainment', y=1.03, fontdict=font2)\n",
    "d4.set_xticklabels(['less than high school', 'some high school', 'high school graduate/GED or equivalent',  \n",
    "                    'some college or AA degree)', 'college graduate or above'], rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7d04c",
   "metadata": {},
   "source": [
    "## 3.5 Feature selection (feature importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e86de1",
   "metadata": {},
   "source": [
    "### Create a function for normalizing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eec9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "def normalize_data(X): \n",
    "    X_std= pd.DataFrame(StandardScaler().fit_transform(X))\n",
    "    X_std.columns= X.columns\n",
    "    return X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aca89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "#partition into X and y\n",
    "target=['mild_dep']\n",
    "drop_features= ['phq9',\n",
    "                'SEQN',\n",
    "                'DPQ010', 'DPQ020', 'DPQ030', 'DPQ040', 'DPQ050', 'DPQ060','DPQ070','DPQ080', 'DPQ090',\n",
    "               'mild_dep', 'sev_dep', 'suicidal', 'mod_dep']\n",
    "X = df_merge[df_merge.columns.drop(drop_features)]\n",
    "y= df_merge[target]\n",
    "#normalize predictors\n",
    "X= normalize_data(X)\n",
    "# training and validation sets split\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "print('Training_X: ', train_X.shape)\n",
    "print('Validation_X: ', valid_X.shape)\n",
    "print('Training_y: ', train_y.shape)\n",
    "print('Validation_y: ', valid_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c6074",
   "metadata": {},
   "source": [
    "### XGboost for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916f14d",
   "metadata": {},
   "source": [
    "We used XGBoost to estimate the importance of features and selected the top 30 features with highest importance. Importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model. Importance is calculated from each single decision tree by the among that each attribute split improves the performance measure, weighted by the number of observations the node is responsible for. Feature importances were then averaged across all trees in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c06f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "xgboost = XGBClassifier()\n",
    "xgboost.fit(train_X, train_y)\n",
    "importance= xgboost.feature_importances_\n",
    "columns= df_merge.columns\n",
    "df = pd.DataFrame({'feature': train_X.columns, 'importance': importance})\n",
    "df = df.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4a7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select top 30 features \n",
    "df30= df[:30]\n",
    "df30.columns=['variable', 'importance']\n",
    "df30['variable'] = df30['variable'].apply(lambda x: x.upper())\n",
    "df30 = pd.merge(left=df30, right=cbook, left_on='variable', right_on='variable', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c1abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81160ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "classificationSummary(valid_y, xgboost.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6957815",
   "metadata": {},
   "source": [
    "#### above shows the problem of imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e290685",
   "metadata": {},
   "source": [
    "## 3.6 Apply SMOTE to the training set\n",
    "A problem with imbalanced classification is that there are too few examples of the minority class for a model to effectively learn the decision boundary. One way to solve this problem is to oversample the examples in the minority class. SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line. Specifically, a random example from the minority class is first chosen. Then k of the nearest neighbors for that example are found (typically k=5). A randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space. (https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0049d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fb39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreate X,y for mild depression\n",
    "target=['mild_dep']\n",
    "drop_features= ['phq9',\n",
    "                'SEQN',\n",
    "                'DPQ010', 'DPQ020', 'DPQ030', 'DPQ040', 'DPQ050', 'DPQ060','DPQ070','DPQ080', 'DPQ090',\n",
    "               'mild_dep', 'sev_dep', 'suicidal', 'mod_dep']\n",
    "X = df_merge[df_merge.columns.drop(drop_features)]\n",
    "y= df_merge[target]\n",
    "#normalize predictors\n",
    "X= normalize_data(X)\n",
    "# training and validation sets split\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "print('Training_X: ', train_X.shape)\n",
    "print('Validation_X: ', valid_X.shape)\n",
    "print('Training_y: ', train_y.shape)\n",
    "print('Validation_y: ', valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b15f8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f65965",
   "metadata": {},
   "source": [
    "### The combination of SMOTE and under-sampling (trim the majority class) performs bettern than plain under-sampling (https://arxiv.org/abs/1106.1813)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3704f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2610f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversample the minority class to have 40% the number of examples of the majority class\n",
    "over = SMOTE(sampling_strategy=0.4)\n",
    "#reduce the number of examples in the majority class to have 50% more than the minority class\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y=pipeline.fit_resample(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcaf05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set remain the same\n",
    "valid_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26aedad",
   "metadata": {},
   "source": [
    "### Re-run feature selection using the more balanced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.fit(train_X, train_y)\n",
    "importance= xgboost.feature_importances_\n",
    "columns= df_merge.columns\n",
    "df = pd.DataFrame({'feature': train_X.columns, 'importance': importance})\n",
    "df = df.sort_values('importance', ascending=False)\n",
    "#select top 20 features \n",
    "df20= df[:20]\n",
    "df20.columns=['variable', 'importance']\n",
    "df20['variable'] = df20['variable'].apply(lambda x: x.upper())\n",
    "df20 = pd.merge(left=df20, right=cbook, left_on='variable', right_on='variable', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a91ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20.to_csv(r'df20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bda0a",
   "metadata": {},
   "source": [
    "### The classification results are improved (more true positive) after balancing data\n",
    "However, this does not fully solve the problem of having way too fewer minority than majority class in the target variable. One could applied resampling strategies as we did to both training and testing sets to get a better results in this regards. But we decided to remain the testing set \"real\" to reduced bias from resampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82d3e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classificationSummary(valid_y, xgboost.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5f01f",
   "metadata": {},
   "source": [
    "## 3.7 Selected variables and correlation matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b70f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list= df20.variable.tolist()\n",
    "var_list.append('mild_dep')\n",
    "print(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8670aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final dfs of balanced training data \n",
    "train_y= train_y.filter(var_list)\n",
    "train_X= train_X.filter(var_list)\n",
    "#final testing set \n",
    "valid_y= valid_y.filter(var_list)\n",
    "valid_X= valid_X.filter(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b60cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20052b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plt.subplots(figsize=(6,6))\n",
    "corr=train_X.corr()\n",
    "sns.heatmap(corr, cmap=sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get highly correlated pairs, ranked by absolute correlation values \n",
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_abs_correlations(train_X, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5032a7d",
   "metadata": {},
   "source": [
    "Narrowed down to 20 predictors; some of them are correlated but since we are interested in prediction instead of inference, this level of multicolineraity between variables is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b837f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8f80a",
   "metadata": {},
   "source": [
    "# 4. Shortlist promising models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9d6ba",
   "metadata": {},
   "source": [
    "The training set is used to fit a few candidate models with repeated 10-folds cross-validation. We evaluated these models using average accuracy scores and average Receiver Operation Characteristics (ROC) Area Under Curve (AUC) scores from the cross-validation. The AUC score is a more unbiased estimate with imbalanced classification like ours (Brownlee, 2021). After an optimal model is selected based on the best cross-validation results, we re-trained the selected model using the full training set. This trained model would be our final model and its performance would be evaluated for its AUC score using the held-out test set. \n",
    "\n",
    "We used multiple supervised learning models for classification of moderate depression. We started with a **logistic regression** model and a **decision tree classification** as our baseline models. We then used ensemble methods that synthesize the results of multiple learning algorithms to achieve better predictive performance over a single estimator. These ensemble models include **random forests, adaptive boosting, and gradient boosting**. Grid search was used in tuning hyper-parameters of these models for the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c648a",
   "metadata": {},
   "source": [
    "## 4.1 Baseline model: logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57872fa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit=LogisticRegression()\n",
    "logit.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationSummary(train_y, logit.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee32e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "#cross-validation \n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "scores = cross_val_score(logit, train_X,train_y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef= logit.coef_\n",
    "coef= coef.flatten()\n",
    "columns= train_X.columns\n",
    "df = pd.DataFrame({'feature': columns, \n",
    "                   'coefficients': coef})\n",
    "df = df.sort_values('coefficients', ascending=False)\n",
    "df.columns=['variable', 'coefficients']\n",
    "df['variable'] = df['variable'].apply(lambda x: x.upper())\n",
    "df = pd.merge(left=df, right=cbook, left_on='variable', right_on='variable', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6f975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "logitsm= sm.Logit(train_y, train_X).fit()\n",
    "logitsm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0bb67",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b65421",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=[6,6])\n",
    "clf= logit\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train,test in cv.split(train_X,train_y):\n",
    "    prediction = clf.fit(train_X.iloc[train],train_y.iloc[train]).predict_proba(train_X.iloc[test])\n",
    "    fpr, tpr, t = roc_curve(train_y.iloc[test], prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.3f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC of logistic regression with 10-fold cross validation')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d4dabf",
   "metadata": {},
   "source": [
    "## 4.2 Baseline model: Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ffd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,RandomizedSearchCV \n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': list(range(2,10)), \n",
    "    'min_samples_split': list(range(2,6))\n",
    "}\n",
    "\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, \n",
    "                          n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print('initial score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "dtree = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569139bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation using training set\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "scores = cross_val_score(dtree, train_X,train_y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa3ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=[6,6])\n",
    "clf= dtree\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train,test in cv.split(train_X,train_y):\n",
    "    prediction = clf.fit(train_X.iloc[train],train_y.iloc[train]).predict_proba(train_X.iloc[test])\n",
    "    fpr, tpr, t = roc_curve(train_y.iloc[test], prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.3f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC of decision tree classifier with 10-fold cross validation')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a2b39",
   "metadata": {},
   "source": [
    "## 4.3 Tree-based ensemble classification models: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,RandomizedSearchCV \n",
    "\n",
    "param_grid = {\n",
    "    'max_leaf_nodes': list(range(2, 100)),\n",
    "    'min_samples_split': [3,4,5,7]\n",
    "}\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, \n",
    "                          n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print('initial score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "rf = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fceb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation using training set\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "scores = cross_val_score(rf, train_X,train_y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c011f",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=[6,6])\n",
    "clf= rf\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train,test in cv.split(train_X,train_y):\n",
    "    prediction = clf.fit(train_X.iloc[train],train_y.iloc[train]).predict_proba(train_X.iloc[test])\n",
    "    fpr, tpr, t = roc_curve(train_y.iloc[test], prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.3f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('random forest classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3c346",
   "metadata": {},
   "source": [
    "## 4.4 Tree-based ensemble classification models: AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [40, 50, 60],\n",
    "    'learning_rate': [1, 1.2, 1.5, 1.9]\n",
    "}\n",
    "gridSearch = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid, cv=5, \n",
    "                          n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print('initial score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "ada = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation using training set\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "scores = cross_val_score(ada, train_X,train_y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427254b",
   "metadata": {},
   "source": [
    "### ROC curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize=[6,6])\n",
    "clf= ada\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train,test in cv.split(train_X,train_y):\n",
    "    prediction = clf.fit(train_X.iloc[train],train_y.iloc[train]).predict_proba(train_X.iloc[test])\n",
    "    fpr, tpr, t = roc_curve(train_y.iloc[test], prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.3f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('adaptive boosting')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2552b",
   "metadata": {},
   "source": [
    "## 4.5 Tree-based ensemble classification models: Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [60, 70, 80],\n",
    "    'max_depth': [ 7,8,9], \n",
    "    'min_impurity_decrease': [0.1, 0.2, 0.3]\n",
    "}\n",
    "gridSearch = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=5, \n",
    "                          n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print('initial score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "gradient = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b77f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation using training set\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "scores = cross_val_score(gradient, train_X,train_y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5acd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plt.figure(figsize=[6,6])\n",
    "clf= gradient\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train,test in cv.split(train_X,train_y):\n",
    "    prediction = clf.fit(train_X.iloc[train],train_y.iloc[train]).predict_proba(train_X.iloc[test])\n",
    "    fpr, tpr, t = roc_curve(train_y.iloc[test], prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.3f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('gradient boosting')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8eee6",
   "metadata": {},
   "source": [
    "## 4.6 Tree-based ensemble classification models: XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [60, 70, 80],\n",
    "    'max_depth': [ 7,8,9], \n",
    "    'min_impurity_decrease': [0.1, 0.2, 0.3]\n",
    "}\n",
    "gridSearch = GridSearchCV(XGBClassifier(random_state=42), param_grid, cv=5, \n",
    "                          n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print('initial score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "xgboost = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587af024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation using training set\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "scores = cross_val_score(xgboost, train_X,train_y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413eb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5 = plt.figure(figsize=[6,6])\n",
    "clf= xgboost\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "for train,test in cv.split(train_X,train_y):\n",
    "    prediction = clf.fit(train_X.iloc[train],train_y.iloc[train]).predict_proba(train_X.iloc[test])\n",
    "    fpr, tpr, t = roc_curve(train_y.iloc[test], prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.3f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('xgboost')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc5245",
   "metadata": {},
   "source": [
    "# 5. Evaluate the best model in the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ddf17",
   "metadata": {},
   "source": [
    "## 5.1 Test it in the held-out test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb9077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528f9e3",
   "metadata": {},
   "source": [
    "We decide to use the Random Forest model as the final model because it has the highest AUC, which is our major consideration of model performance. It also has a pretty high accuracy score, very close to the highest ones achieved by AdaBoost and Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89732d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain the selected model with full training set \n",
    "rf= sklearn.base.clone(rf)\n",
    "rf.fit(train_X, train_y)\n",
    "#test in the hold-out test set\n",
    "classificationSummary(valid_y, rf.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_proba = rf.predict_proba(valid_X)[::,1]\n",
    "\n",
    "#calculate AUC of model\n",
    "auc = metrics.roc_auc_score(valid_y, y_pred_proba)\n",
    "\n",
    "#print AUC score\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74cef4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "plot_roc_curve(rf, valid_X, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c27eb",
   "metadata": {},
   "source": [
    "For model performance, we are more interested in AUC than accuracy scores because of our imbalanced data as well as our research aim, where we care about the sensitivity and specificity of our model. Our final best model has an AUC of 0.82. In general, 0.7 to 0.8 is considered acceptable, 0.8 to 0.9 is considered excellent, and more than 0.9 is considered outstanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff4486",
   "metadata": {},
   "source": [
    "## 5.2 Final visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add codebook names \n",
    "importance= rf.feature_importances_\n",
    "columns= train_X.columns\n",
    "df = pd.DataFrame({'feature': columns, \n",
    "                   'importance': importance})\n",
    "df = df.sort_values('importance', ascending=False)\n",
    "df.columns=['variable', 'importance']\n",
    "df['variable'] = df['variable'].apply(lambda x: x.upper())\n",
    "df = pd.merge(left=df, right=cbook, left_on='variable', right_on='variable', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269c61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_feature_importance(rf.feature_importances_,df.label,'RANDOM FOREST ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
